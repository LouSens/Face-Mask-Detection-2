# Real-Time Face Mask Detection

A continuation of a group project originally developed during my first-year undergraduate (third semester). This version significantly improves the modelâ€™s accuracy and generalization across various real-world conditions, making it robust against challenges like lighting variations, crowd density, and camera sensitivity.

## âœ¨ Key Improvements

* **High accuracy and validation accuracy** with minimal overfitting.
* **Real-time detection** using webcam input.
* Enhanced model generalization to handle various environments and lighting conditions.

---

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ model.py             # Training pipeline: data loading, model building, training, saving
â”œâ”€â”€ mask_detection.py    # Real-time detection with webcam
â”œâ”€â”€ plotting.py          # Visualizes training history
â”œâ”€â”€ training_history.pkl # Saved training metrics
â”œâ”€â”€ mask_detector_final.keras # Final trained model
```

---

## ðŸš€ Getting Started

### 1. Install Dependencies

```bash
pip install tensorflow opencv-python matplotlib scikit-learn
```

### 2. Download Dataset from Hugging Face

The dataset used for training is stored externally due to its large size. You can access and download it from the Hugging Face repository:

ðŸ”— **[Face Mask Detection Dataset on Hugging Face](https://huggingface.co/datasets/HuangYiYang/Face-Mask-Detection-Dataset)**

Once downloaded, place the dataset in a folder named `dataset/` with the following structure:

```
dataset/
â”œâ”€â”€ with_mask/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ without_mask/
    â”œâ”€â”€ image2.jpg
    â””â”€â”€ ...
```

> Make sure the local folder structure matches this layout to ensure the script runs correctly.

### 3. Train the Model

Run the training script:

```bash
python model.py
```

This will:

* Train and fine-tune a MobileNetV2 model
* Save the model as `mask_detector_final.keras`
* Save training history in `training_history.pkl`

### 4. Visualize Training Metrics

Plot the training/validation accuracy and loss:

```bash
python plotting.py
```

The result will be saved as `training_results_square.png`.

### 5. Run Real-Time Detection

Use your webcam to detect face masks in real time:

```bash
python mask_detection.py
```

Press **`q`** to exit the camera feed.

---

## ðŸ§  Model Architecture

* **Base**: MobileNetV2 (pre-trained on ImageNet)
* **Head**: Custom dense layers with dropout & batch normalization
* **Loss Function**: Binary Crossentropy
* **Optimization**: Adam with learning rate decay and early stopping

---

## ðŸ“Š Performance

The model achieves:

* High training & validation accuracy (comparable across both)
* Stable loss curves without overfitting
* Real-world robustness to lighting, angles, and distance

---

## ðŸ‘¤ Author

Developed and maintained by **\David Huang** â€” a first-year undergraduate student. This project is a personal improvement on a previously group-developed version, with major enhancements in performance and reliability.

---

## ðŸ“„ License

This project is for academic use and demonstration purposes. For commercial use, please contact the author.
